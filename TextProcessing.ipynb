{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    " 1. Clean Data\n",
    " 2. Transform Data \n",
    " 3. Create small labeled training datasets for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some config parameters\n",
    "\n",
    "DATA_PATH=Path('Data/')\n",
    "DATA_PATH.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH/'train.csv', header = None)\n",
    "train.rename(columns = {0: 'rating', 1: 'review'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATA_PATH/'test.csv', header = None)\n",
    "test.rename(columns = {0: 'rating', 1: 'review'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings in train set: 650000\n",
      "Number of ratings in test set: 50000\n",
      "Number of 5.0 ratings in train set: 130000\n"
     ]
    }
   ],
   "source": [
    "print('Number of ratings in train set:', train.shape[0])\n",
    "print ('Number of ratings in test set:', test.shape[0])\n",
    "print ('Number of 5.0 ratings in train set:', train.loc[train.rating == 5].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "#import unicodedata\n",
    "import unidecode\n",
    "\n",
    "\n",
    "\n",
    "def clean_html(text):\n",
    "    \"\"\"remove html div tags if there is any\"\"\"\n",
    "    text = str(text)\n",
    "    return re.sub('<.*?>', ' ', text)\n",
    "\n",
    "def remove_repeats(string, n, join=True):\n",
    "    count = 0\n",
    "    output = []\n",
    "    last = ''\n",
    "    for c in string:\n",
    "        if c == last:\n",
    "            count = count + 1\n",
    "        else:\n",
    "            count = 0\n",
    "            last = c\n",
    "        if count < n:\n",
    "            output.append(c)\n",
    "    if join:\n",
    "        return \"\".join(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def preprocess_text(text, front_pad='\\n ', end_pad=' ', clean_markup=True,\n",
    "                clean_unicode=True, encode='utf-8', limit_repeats=3):\n",
    "    \"\"\"\n",
    "    Processes utf-8 encoded text according to the criterion specified in seciton 4 of \n",
    "    https://arxiv.org/pdf/1704.01444.pdf (Radford et al).\n",
    "    Follow Kant et al. codes with some fixed-up\n",
    "    \"\"\"\n",
    "    if clean_markup:\n",
    "        text = clean_html(text)\n",
    "\n",
    "    if clean_unicode:\n",
    "        text = unidecode.unidecode(text)\n",
    "\n",
    "    text = html.unescape(text)\n",
    "    text = text.replace('\\\\n',\"\\n\").replace('\\\\\"', '\"').replace(' @.@ ','.').replace(\n",
    "                        ' @-@ ','-').replace('\\\\', ' \\\\ ').replace('\\n',' ').strip()\n",
    "    text = text.split()\n",
    "\n",
    "    if limit_repeats > 0:\n",
    "        remove_repeats(text, limit_repeats, join=False)\n",
    "\n",
    "    text = front_pad+(\" \".join(text))+end_pad\n",
    "\n",
    "    if encode is not None:\n",
    "        text = text.encode(encoding=encode)\n",
    "        text = ''.join(chr(c) for c in text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cleaned_text'] = train.review.apply(lambda t: preprocess_text(t))\n",
    "test['cleaned_text'] = test.review.apply(lambda t: preprocess_text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffer the reviews\n",
    "train2 = train.sample(frac=1, random_state= 42 ).reset_index(drop=True)\n",
    "test2 = test.sample(frac = 1, random_state= 42).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed text to disk\n",
    "\n",
    "train_clean = train2[['rating','cleaned_text']]\n",
    "test_clean = test2[['rating','cleaned_text']]\n",
    "\n",
    "train_clean.to_csv(DATA_PATH/'train_cleaned.csv', header=False, index=False )\n",
    "test_clean.to_csv(DATA_PATH/'test_cleaned.csv', header=False, index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "train_clean = pd.read_csv(DATA_PATH/'train_cleaned.csv', header = None)\n",
    "train_clean.rename(columns = {0: 'label', 1: 'text'}, inplace = True)\n",
    "test_clean = pd.read_csv(DATA_PATH/'test_cleaned.csv', header = None)\n",
    "test_clean.rename(columns = {0: 'label', 1: 'text'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create onehot encoding columns for rating\n",
    "label_col = pd.get_dummies(train_clean['label'], prefix = 'rating')\n",
    "\n",
    "train_clean2 = train_clean.copy()\n",
    "train_clean2 = train_clean2.drop('label', axis =1  )\n",
    "train_clean2 = train_clean2.join(label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat one hot encoding for test data\n",
    "label_col_test = pd.get_dummies(test_clean['label'], prefix = 'rating')\n",
    "\n",
    "test_clean2 = test_clean.copy()\n",
    "test_clean2 = test_clean2.drop('label', axis =1  )\n",
    "test_clean2 = test_clean2.join(label_col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to disk\n",
    "train_clean2.to_csv(DATA_PATH/'train_onehot.csv', index = False)\n",
    "test_clean2.to_csv(DATA_PATH/'test_onehot.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create subsets of data for experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_clean2 = pd.read_csv(DATA_PATH/'train_onehot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_group(df):\n",
    "    print('#rating 1:', sum(df.rating_1))\n",
    "    print('#rating 2:', sum(df.rating_2))\n",
    "    print('#rating 3:', sum(df.rating_3))\n",
    "    print('#rating 4:', sum(df.rating_4))\n",
    "    print('#rating 5:', sum(df.rating_5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#50 examples\n",
    "train_50 = train_clean2.sample(frac=1/13000, random_state= 123 ).reset_index(drop=True)\n",
    "train_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rating 1: 9\n",
      "#rating 2: 10\n",
      "#rating 3: 12\n",
      "#rating 4: 14\n",
      "#rating 5: 5\n"
     ]
    }
   ],
   "source": [
    "print_group(train_50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#100 examples\n",
    "train_100 = train_clean2.sample(frac=1/6500, random_state= 10000).reset_index(drop=True)\n",
    "train_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rating 1: 29\n",
      "#rating 2: 10\n",
      "#rating 3: 13\n",
      "#rating 4: 21\n",
      "#rating 5: 27\n"
     ]
    }
   ],
   "source": [
    "print_group(train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#500 examples\n",
    "train_500 = train_clean2.sample(frac=1/1300, random_state= 421).reset_index(drop=True)\n",
    "train_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rating 1: 105\n",
      "#rating 2: 94\n",
      "#rating 3: 76\n",
      "#rating 4: 116\n",
      "#rating 5: 109\n"
     ]
    }
   ],
   "source": [
    "print_group(train_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1000 examples\n",
    "train_1000 = train_clean2.sample(frac=1/650, random_state= 4222).reset_index(drop=True)\n",
    "train_1000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rating 1: 217\n",
      "#rating 2: 171\n",
      "#rating 3: 221\n",
      "#rating 4: 181\n",
      "#rating 5: 210\n"
     ]
    }
   ],
   "source": [
    "print_group(train_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n First of all i'm not a big fan of buffet, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n Thanks Yelp. I was looking for the words to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n Service was so-so. They were receiving a de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n Stamoolis Brothers is one of the Strip Dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n I want to give a 2 stars because the servic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  \\n First of all i'm not a big fan of buffet, i...\n",
       "1      2  \\n Thanks Yelp. I was looking for the words to...\n",
       "2      3  \\n Service was so-so. They were receiving a de...\n",
       "3      3  \\n Stamoolis Brothers is one of the Strip Dist...\n",
       "4      1  \\n I want to give a 2 stars because the servic..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3000 examples\n",
    "train_3000 = train_clean.sample(frac=2/325, random_state= 421).reset_index(drop=True)\n",
    "\n",
    "  # Drop 1000 examples \n",
    "idx_drop = list(train_3000[train_3000.label == 3].index[:400])\n",
    "idx_drop.extend(list(train_3000[train_3000.label ==4].index[:100]))\n",
    "idx_drop.extend(list(train_3000[train_3000.label == 1].index[:500]))\n",
    "\n",
    "train_3000 = train_3000.drop(idx_drop)\n",
    "\n",
    "#Transform back to one hot\n",
    "label_col_3000 = pd.get_dummies(train_3000['label'], prefix = 'rating')\n",
    "\n",
    "train_3000 = train_3000.drop('label', axis =1  )\n",
    "train_3000 = train_3000.join(label_col_3000)\n",
    "\n",
    "train_3000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rating 1: 326\n",
      "#rating 2: 754\n",
      "#rating 3: 428\n",
      "#rating 4: 680\n",
      "#rating 5: 812\n"
     ]
    }
   ],
   "source": [
    "print_group(train_3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5000 examples\n",
    "train_5000 = train_clean.sample(frac=3/325, random_state= 4).reset_index(drop=True)\n",
    "\n",
    "  # Drop 1000 examples \n",
    "idx_drop = list(train_5000[train_5000.label == 3].index[:400])\n",
    "idx_drop.extend(list(train_5000[train_5000.label ==4].index[:100]))\n",
    "idx_drop.extend(list(train_5000[train_5000.label == 1].index[:500]))\n",
    "\n",
    "train_5000 = train_5000.drop(idx_drop)\n",
    "\n",
    "#Transform back to one hot\n",
    "label_col_5000 = pd.get_dummies(train_5000['label'], prefix = 'rating')\n",
    "\n",
    "train_5000 = train_5000.drop('label', axis =1  )\n",
    "train_5000 = train_5000.join(label_col_5000)\n",
    "\n",
    "train_5000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rating 1: 681\n",
      "#rating 2: 1205\n",
      "#rating 3: 776\n",
      "#rating 4: 1129\n",
      "#rating 5: 1209\n"
     ]
    }
   ],
   "source": [
    "print_group(train_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all subsets to disk\n",
    "train_50.to_csv(DATA_PATH/'experiment/train_50.csv', index=False )\n",
    "train_100.to_csv(DATA_PATH/'experiment/train_100.csv', index=False )\n",
    "train_500.to_csv(DATA_PATH/'experiment/train_500.csv', index=False )\n",
    "train_1000.to_csv(DATA_PATH/'experiment/train_1000.csv', index=False )\n",
    "train_3000.to_csv(DATA_PATH/'experiment/train_3000.csv', index=False )\n",
    "train_5000.to_csv(DATA_PATH/'experiment/train_5000.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_val_train_sets(filename):\n",
    "    name = filename.split('/')[-1].split('.')[0]\n",
    "    df = pd.read_csv(DATA_PATH/filename)\n",
    "    #Split train and val sets\n",
    "    trainset, valset = train_test_split(df, test_size=0.2, random_state=123)\n",
    "    #Save to disk\n",
    "    fname_train = 'experiment/'+name+'_train.csv'\n",
    "    fname_val = 'experiment/'+name+'_val.csv'\n",
    "    trainset.to_csv(DATA_PATH/fname_train, index = False)\n",
    "    valset.to_csv(DATA_PATH/fname_val, index = False)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_val_train_sets('experiment/train_50.csv')\n",
    "split_val_train_sets('experiment/train_100.csv')\n",
    "split_val_train_sets('experiment/train_500.csv')\n",
    "split_val_train_sets('experiment/train_1000.csv')\n",
    "split_val_train_sets('experiment/train_3000.csv')\n",
    "split_val_train_sets('experiment/train_5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
